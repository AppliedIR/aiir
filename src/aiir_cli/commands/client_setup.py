"""Generate LLM client configuration pointing at AIIR API servers.

On SIFT, MCP entries use ``type: http`` in global ``~/.claude.json``.
On remote clients, entries use ``type: streamable-http`` in project
``.mcp.json``.  Runs on the machine where the human sits; points at
gateway / wintools / REMnux endpoints wherever they are.
"""

from __future__ import annotations

import json
import shutil
import sys
from pathlib import Path

from aiir_cli.setup.config_gen import _write_600

# ---------------------------------------------------------------------------
# External reference MCPs (optional, public, no auth)
# ---------------------------------------------------------------------------
_ZELTSER_MCP = {
    "name": "zeltser-ir-writing",
    "type": "streamable-http",
    "url": "https://website-mcp.zeltser.com/mcp",
}

_MSLEARN_MCP = {
    "name": "microsoft-learn",
    "type": "streamable-http",
    "url": "https://learn.microsoft.com/api/mcp",
}

# Forensic deny rules — must match claude-code/settings.json source template
_FORENSIC_DENY_RULES = {"Bash(rm -rf *)", "Bash(mkfs*)", "Bash(dd *)"}

# AIIR backend names — used for uninstall identification.
# External MCPs (zeltser-ir-writing, microsoft-learn) are intentionally excluded
# so uninstall does not remove MCPs the user may have configured independently.
_AIIR_BACKEND_NAMES = {
    "forensic-mcp",
    "case-mcp",
    "sift-mcp",
    "report-mcp",
    "forensic-rag-mcp",
    "windows-triage-mcp",
    "opencti-mcp",
    "wintools-mcp",
    "remnux-mcp",
    "aiir",
}


# ---------------------------------------------------------------------------
# Public entry point
# ---------------------------------------------------------------------------


def cmd_setup_client(args, identity: dict) -> None:
    """Generate LLM client configuration for AIIR endpoints."""
    if getattr(args, "uninstall", False):
        _cmd_uninstall(args)
        return

    if getattr(args, "remote", False):
        _cmd_setup_client_remote(args, identity)
        return

    auto = getattr(args, "yes", False)

    # 1. Resolve parameters from switches (or interactive wizard)
    client = _resolve_client(args, auto)
    sift_url = _resolve_sift(args, auto)
    windows_url = _resolve_windows(args, auto)
    remnux_url = _resolve_remnux(args, auto)
    examiner = _resolve_examiner(args, identity)
    include_zeltser, include_mslearn = _resolve_internet_mcps(args, auto)

    # 2. Build endpoint list
    servers: dict[str, dict] = {}

    if sift_url:
        # Try to discover per-backend endpoints from the running gateway
        backends_discovered = False
        local_token = _read_local_token()
        services = _discover_services(sift_url, local_token)
        if services:
            running = [s for s in services if s.get("started")]
            if running:
                backends_discovered = True
                for s in running:
                    name = s["name"]
                    entry: dict = {
                        "type": "streamable-http",
                        "url": f"{sift_url.rstrip('/')}/mcp/{name}",
                    }
                    if local_token:
                        entry["headers"] = {"Authorization": f"Bearer {local_token}"}
                    servers[name] = entry

        if not backends_discovered:
            # Gateway not reachable or no backends — fall back to aggregate
            entry = {
                "type": "streamable-http",
                "url": _ensure_mcp_path(sift_url),
            }
            if local_token:
                entry["headers"] = {"Authorization": f"Bearer {local_token}"}
            servers["aiir"] = entry

    if windows_url:
        servers["wintools-mcp"] = {
            "type": "streamable-http",
            "url": _ensure_mcp_path(windows_url),
        }

    if remnux_url:
        servers["remnux-mcp"] = {
            "type": "streamable-http",
            "url": _ensure_mcp_path(remnux_url),
        }

    if include_zeltser:
        servers[_ZELTSER_MCP["name"]] = {
            "type": _ZELTSER_MCP["type"],
            "url": _ZELTSER_MCP["url"],
        }

    if include_mslearn:
        servers[_MSLEARN_MCP["name"]] = {
            "type": _MSLEARN_MCP["type"],
            "url": _MSLEARN_MCP["url"],
        }

    if not servers:
        print("No endpoints configured — nothing to write.", file=sys.stderr)
        return

    # 3. Generate config for selected client
    try:
        _generate_config(client, servers, examiner)
    except OSError as e:
        print(f"Failed to write client configuration: {e}", file=sys.stderr)
        sys.exit(1)

    # 4. Print internet MCP summary
    internet_mcps = []
    if include_zeltser:
        internet_mcps.append((_ZELTSER_MCP["name"], _ZELTSER_MCP["url"]))
    if include_mslearn:
        internet_mcps.append((_MSLEARN_MCP["name"], _MSLEARN_MCP["url"]))
    if internet_mcps:
        print("  Internet MCPs:")
        for name, url in internet_mcps:
            print(f"    {name:<25s}{url}")


# ---------------------------------------------------------------------------
# SIFT detection
# ---------------------------------------------------------------------------


def _is_sift() -> bool:
    """Return True if running on a SIFT workstation (gateway.yaml exists)."""
    return (Path.home() / ".aiir" / "gateway.yaml").is_file()


# ---------------------------------------------------------------------------
# Parameter resolution
# ---------------------------------------------------------------------------


def _resolve_client(args, auto: bool) -> str:
    val = getattr(args, "client", None)
    if val:
        return val
    # Always prompt for client — no sensible default (AIIR is LLM-agnostic)
    return _wizard_client()


def _resolve_sift(args, auto: bool) -> str:
    val = getattr(args, "sift", None)
    if val is not None:
        return val  # explicit switch (even "" means "no sift")

    # Auto-detect local gateway
    default = "http://127.0.0.1:4508"
    if auto:
        return default

    detected = _probe_health(default)
    if detected:
        status = "detected running"
    else:
        status = "not detected, will use default"

    print("\n--- SIFT Workstation (Gateway) ---")
    print("The AIIR gateway runs on your SIFT workstation and provides")
    print("forensic tools (forensic-mcp, sift-mcp, forensic-rag, etc.).")
    print()
    print(f"  Default:  {default}  ({status})")
    print("  Format:   URL              Example: http://10.0.0.2:4508")
    print('  Enter "skip" to omit.')

    answer = _prompt("\nSIFT gateway URL", default)
    if answer.lower() == "skip":
        return ""
    return answer


def _resolve_windows(args, auto: bool) -> str:
    val = getattr(args, "windows", None)
    if val is not None:
        return _normalise_url(val, 4624) if val else ""
    if auto:
        return ""

    print("\n--- Windows Forensic Workstation ---")
    print("If you have a Windows workstation running wintools-mcp, enter its")
    print("IP address or hostname. The default port is 4624.")
    print()
    print("  Format:   IP or IP:PORT     Examples: 192.168.1.20, 10.0.0.5:4624")
    print("  Find it:  On the Windows box, run: ipconfig | findstr IPv4")

    answer = _prompt("\nWindows endpoint", "skip")
    if answer.lower() == "skip":
        return ""
    return _normalise_url(answer, 4624)


def _resolve_remnux(args, auto: bool) -> str:
    val = getattr(args, "remnux", None)
    if val is not None:
        return _normalise_url(val, 3000) if val else ""
    if auto:
        return ""

    print("\n--- REMnux Malware Analysis Workstation ---")
    print("If you have a REMnux VM running remnux-mcp, enter its IP address")
    print("or hostname. The default port is 3000.")
    print()
    print("  Format:   IP or IP:PORT     Examples: 192.168.1.30, 10.0.0.10:3000")
    print("  Find it:  On the REMnux box, run: ip addr show | grep inet")

    answer = _prompt("\nREMnux endpoint", "skip")
    if answer.lower() == "skip":
        return ""
    return _normalise_url(answer, 3000)


def _resolve_internet_mcps(args, auto: bool) -> tuple[bool, bool]:
    """Resolve which internet MCPs to include. Returns (zeltser, mslearn)."""
    no_mslearn = getattr(args, "no_mslearn", False)

    if auto:
        return (True, not no_mslearn)

    print("\n--- Internet MCPs (public, no auth required) ---")
    print("These connect your LLM client directly to public knowledge servers.")
    print()
    print("  Zeltser IR Writing   Required for the IR reporting feature")

    include_mslearn = _prompt_yn(
        "  Microsoft Learn      Search Microsoft docs and code samples",
        default=True,
    )

    return (True, include_mslearn)


def _resolve_examiner(args, identity: dict) -> str:
    val = getattr(args, "examiner", None)
    if val:
        return val
    return identity.get("examiner", "unknown")


# ---------------------------------------------------------------------------
# Interactive wizard
# ---------------------------------------------------------------------------


def _wizard_client() -> str:
    print("\n=== AIIR Client Configuration ===")
    print("Which LLM client will connect to your AIIR endpoints?\n")
    print("  1. Claude Code      CLI agent (writes .mcp.json + CLAUDE.md)")
    print("  2. Claude Desktop   Desktop app (writes claude_desktop_config.json)")
    print("  3. Cursor           IDE (writes .cursor/mcp.json + .cursor/rules/)")
    print("  4. LibreChat        Web UI (writes librechat_mcp.yaml)")
    print("  5. ChatGPT Desktop  Manual setup (prints instructions)")
    print("  6. Other / manual   Raw JSON config for any MCP client")

    choice = _prompt("\nChoose", "1")
    return {
        "1": "claude-code",
        "2": "claude-desktop",
        "3": "cursor",
        "4": "librechat",
        "5": "chatgpt",
        "6": "other",
    }.get(choice, "other")


def _prompt(message: str, default: str = "") -> str:
    try:
        if default:
            answer = input(f"{message} [{default}]: ").strip()
            return answer or default
        return input(f"{message}: ").strip()
    except EOFError:
        return default


def _prompt_yn(message: str, default: bool = True) -> bool:
    """Prompt for a yes/no answer. Returns bool."""
    hint = "Y/n" if default else "y/N"
    try:
        answer = input(f"{message} [{hint}]: ").strip().lower()
    except EOFError:
        return default
    if not answer:
        return default
    return answer in ("y", "yes")


# ---------------------------------------------------------------------------
# Config generation
# ---------------------------------------------------------------------------


def _generate_config(client: str, servers: dict, examiner: str) -> None:
    config = {"mcpServers": servers}
    sift = _is_sift()

    if client == "claude-code":
        if sift:
            # SIFT: write MCP servers globally to ~/.claude.json
            global_config = Path.home() / ".claude.json"
            # Transform type to "http" for global scope
            global_servers = {}
            for name, entry in servers.items():
                g_entry = dict(entry)
                g_entry["type"] = "http"
                global_servers[name] = g_entry
            _merge_and_write(global_config, {"mcpServers": global_servers})
            print(f"  Generated: {global_config} (global MCP servers)")
        else:
            # Non-SIFT: write .mcp.json to cwd
            output = Path.cwd() / ".mcp.json"
            _merge_and_write(output, config)
            print(f"  Generated: {output}")

        _deploy_claude_code_assets(Path.cwd())
        print(f"  Examiner:  {examiner}")
        print("")
        print("  Forensic controls deployed:")
        print("    Sandbox:     enabled (Bash writes restricted)")
        print("    Audit hook:  forensic-audit.sh (captures all Bash commands)")
        print("    Provenance:  enforced (findings require evidence trail)")
        print("    Discipline:  FORENSIC_DISCIPLINE.md + TOOL_REFERENCE.md")

        if sift:
            print("")
            print("  Forensic controls deployed globally.")
            print("  Claude Code can be launched from any directory on this machine.")
            print("  Audit logging, permission guardrails, and MCP tools will always apply.")

    elif client == "claude-desktop":
        output = Path.home() / ".config" / "claude" / "claude_desktop_config.json"
        _merge_and_write(output, config)
        print(f"  Generated: {output}")
        agents_md = _find_agents_md()
        print("")
        print("  To enable forensic discipline guidance:")
        print("    1. Open Claude Desktop")
        print("    2. Create a new Project (or open an existing one)")
        print("    3. Click 'Set project instructions'")
        if agents_md:
            print(f"    4. Paste the contents of: {agents_md}")
        else:
            print("    4. Paste the contents of AGENTS.md from the sift-mcp repo")
        print("")
        print("  The MCP servers also provide instructions automatically via")
        print("  the MCP protocol. Project instructions provide additional")
        print("  context for your investigation workflow.")

    elif client == "cursor":
        output = Path.cwd() / ".cursor" / "mcp.json"
        _merge_and_write(output, config)
        _write_cursor_rules()
        print(f"  Generated: {output}")

    elif client == "librechat":
        output = Path.cwd() / "librechat_mcp.yaml"
        _write_librechat_yaml(output, servers)
        print(f"  Generated: {output}")
        print("  Merge into your librechat.yaml under the mcpServers key.")

    elif client == "chatgpt":
        print("\n  ChatGPT Desktop setup (manual):\n")
        print("    1. Open ChatGPT Desktop → Settings → Developer")
        print("    2. Enable Developer Mode")
        print("    3. Add MCP connector for each backend:")
        for name, info in servers.items():
            url = info.get("url", "")
            if url:
                print(f"       {name}: {url}")
        # Show token if present in any entry
        sample = next(iter(servers.values()), {})
        token = (sample.get("headers") or {}).get("Authorization", "")
        if token:
            print(f"    4. Add Authorization header: {token}")
        print("")
        print("    5. Go to Settings → Personalization → Custom Instructions")
        print("    6. Paste the forensic discipline summary (note: 1500 char limit)")
        print("")
        print("  Note: ChatGPT has a 1500-character limit on custom instructions.")
        print("  The MCP servers provide full discipline via the protocol.")

    else:
        # Manual / other — just dump JSON
        output = Path.cwd() / "aiir-mcp-config.json"
        _merge_and_write(output, config)
        print(f"  Generated: {output}")


def _find_claude_code_assets() -> Path | None:
    """Locate the sift-mcp/claude-code/ directory.

    Search order:
    1. Well-known paths relative to sift-mcp installation
    2. ~/.aiir/src/sift-mcp/claude-code/
    3. /opt/aiir/sift-mcp/claude-code/
    """
    candidates = [
        lambda: Path.home() / ".aiir" / "src" / "sift-mcp" / "claude-code",
        lambda: Path.home() / "aiir" / "sift-mcp" / "claude-code",
        lambda: Path("/opt/aiir/sift-mcp/claude-code"),
    ]

    # Also check gateway.yaml for sift-mcp source path
    gw_config = Path.home() / ".aiir" / "gateway.yaml"
    if gw_config.is_file():
        try:
            import yaml
            config = yaml.safe_load(gw_config.read_text()) or {}
            src_dir = config.get("sift_mcp_dir", "")
            if src_dir:
                candidate = Path(src_dir) / "claude-code"
                if candidate.is_dir():
                    return candidate
        except Exception:
            pass

    for fn in candidates:
        p = fn()
        if p.is_dir():
            return p
    return None


def _merge_settings(target: Path, source: Path) -> None:
    """Deep-merge hooks, permissions, and sandbox keys from source into target."""
    existing = {}
    if target.is_file():
        try:
            existing = json.loads(target.read_text())
        except json.JSONDecodeError:
            pass
        except OSError:
            pass

    try:
        incoming = json.loads(source.read_text())
    except (json.JSONDecodeError, OSError) as e:
        print(f"  Warning: could not read source settings: {e}", file=sys.stderr)
        return

    # Deep-merge hooks: merge arrays for each hook type
    if "hooks" in incoming:
        existing_hooks = existing.setdefault("hooks", {})
        for hook_type, entries in incoming["hooks"].items():
            if hook_type not in existing_hooks:
                existing_hooks[hook_type] = entries
            else:
                # Deduplicate by comparing command strings
                existing_cmds = set()
                for entry in existing_hooks[hook_type]:
                    for h in entry.get("hooks", []):
                        existing_cmds.add(h.get("command", ""))
                for entry in entries:
                    new_cmds = [h.get("command", "") for h in entry.get("hooks", [])]
                    if not any(c in existing_cmds for c in new_cmds):
                        existing_hooks[hook_type].append(entry)

    # Merge permissions.deny (additive, preserve allow/ask/defaultMode)
    if "permissions" in incoming:
        existing_perms = existing.setdefault("permissions", {})
        if "deny" in incoming["permissions"]:
            existing_deny = set(existing_perms.get("deny", []))
            for rule in incoming["permissions"]["deny"]:
                existing_deny.add(rule)
            existing_perms["deny"] = sorted(existing_deny)

    # Merge sandbox config
    if "sandbox" in incoming:
        existing.setdefault("sandbox", {}).update(incoming["sandbox"])

    target.parent.mkdir(parents=True, exist_ok=True)
    _write_600(target, json.dumps(existing, indent=2) + "\n")


def _deploy_hook(source: Path, target: Path) -> None:
    """Copy hook script and set executable permissions."""
    target.parent.mkdir(parents=True, exist_ok=True)
    shutil.copy2(source, target)
    target.chmod(0o755)


def _deploy_claude_md(assets_dir: Path, target: Path) -> None:
    """Copy the real CLAUDE.md from assets directory to target."""
    src = assets_dir / "CLAUDE.md"
    if not src.is_file():
        print("  Warning: CLAUDE.md not found in assets.", file=sys.stderr)
        return
    if target.is_file():
        backup = target.with_suffix(".md.bak")
        shutil.copy2(target, backup)
        print(f"  Backed up: {target.name} -> {backup.name}")
    target.parent.mkdir(parents=True, exist_ok=True)
    shutil.copy2(src, target)
    print(f"  Deployed:  CLAUDE.md -> {target}")


def _deploy_global_rules(assets_dir: Path) -> None:
    """Deploy discipline docs to ~/.claude/rules/ (SIFT only)."""
    rules_dir = Path.home() / ".claude" / "rules"
    rules_dir.mkdir(parents=True, exist_ok=True)

    # FORENSIC_DISCIPLINE.md
    src = assets_dir / "FORENSIC_DISCIPLINE.md"
    if src.is_file():
        shutil.copy2(src, rules_dir / "FORENSIC_DISCIPLINE.md")
        print(f"  Copied:    FORENSIC_DISCIPLINE.md -> {rules_dir}")

    # TOOL_REFERENCE.md
    src = assets_dir / "TOOL_REFERENCE.md"
    if src.is_file():
        shutil.copy2(src, rules_dir / "TOOL_REFERENCE.md")
        print(f"  Copied:    TOOL_REFERENCE.md -> {rules_dir}")

    # AGENTS.md
    agents = _find_agents_md()
    if agents:
        shutil.copy2(agents, rules_dir / "AGENTS.md")
        print(f"  Copied:    AGENTS.md -> {rules_dir}")


def _deploy_claude_code_assets(project_dir: Path) -> None:
    """Deploy settings.json, hooks, and doc files for Claude Code.

    Sources from sift-mcp/claude-code/ directory.
    On SIFT: deploys globally (settings to ~/.claude/, hook to ~/.aiir/hooks/).
    On non-SIFT: deploys to project directory.
    """
    assets_dir = _find_claude_code_assets()
    if not assets_dir:
        print(
            "  Note: sift-mcp claude-code assets not found. "
            "Hook and settings deployment skipped."
        )
        return

    sift = _is_sift()

    if sift:
        # --- SIFT global deployment ---

        # Deploy settings.json to ~/.claude/settings.json
        settings_src = assets_dir / "settings.json"
        if settings_src.is_file():
            settings_target = Path.home() / ".claude" / "settings.json"
            _merge_settings(settings_target, settings_src)
            print(f"  Merged:    settings.json -> {settings_target}")

            # Post-merge fixup: replace $CLAUDE_PROJECT_DIR hook path with absolute
            _fixup_global_hook_path(settings_target)

        # Deploy hook script to ~/.aiir/hooks/
        hook_src = assets_dir / "hooks" / "forensic-audit.sh"
        if hook_src.is_file():
            hook_target = Path.home() / ".aiir" / "hooks" / "forensic-audit.sh"
            _deploy_hook(hook_src, hook_target)
            print(f"  Deployed:  forensic-audit.sh -> {hook_target}")

        # Deploy CLAUDE.md globally
        _deploy_claude_md(assets_dir, Path.home() / ".claude" / "CLAUDE.md")

        # Deploy discipline docs to ~/.claude/rules/
        _deploy_global_rules(assets_dir)

        # Also deploy docs to project root (contextual, harmless)
        for doc_name in ("FORENSIC_DISCIPLINE.md", "TOOL_REFERENCE.md"):
            doc_src = assets_dir / doc_name
            if doc_src.is_file():
                shutil.copy2(doc_src, project_dir / doc_name)
                print(f"  Copied:    {doc_name}")

        # Copy AGENTS.md to project root for non-Claude-Code clients
        _copy_agents_md(project_dir / "AGENTS.md")

    else:
        # --- Non-SIFT project-level deployment ---

        # Deploy settings.json to project
        settings_src = assets_dir / "settings.json"
        if settings_src.is_file():
            settings_target = project_dir / ".claude" / "settings.json"
            _merge_settings(settings_target, settings_src)
            print(f"  Merged:    settings.json -> {settings_target}")

        # Deploy hook script to project
        hook_src = assets_dir / "hooks" / "forensic-audit.sh"
        if hook_src.is_file():
            hook_target = project_dir / ".claude" / "hooks" / "forensic-audit.sh"
            _deploy_hook(hook_src, hook_target)
            print(f"  Deployed:  forensic-audit.sh -> {hook_target}")

        # Deploy CLAUDE.md to project root
        _deploy_claude_md(assets_dir, project_dir / "CLAUDE.md")

        # Copy AGENTS.md to project root
        _copy_agents_md(project_dir / "AGENTS.md")

        # Deploy FORENSIC_DISCIPLINE.md
        discipline_src = assets_dir / "FORENSIC_DISCIPLINE.md"
        if discipline_src.is_file():
            shutil.copy2(discipline_src, project_dir / "FORENSIC_DISCIPLINE.md")
            print(f"  Copied:    FORENSIC_DISCIPLINE.md")

        # Deploy TOOL_REFERENCE.md
        toolref_src = assets_dir / "TOOL_REFERENCE.md"
        if toolref_src.is_file():
            shutil.copy2(toolref_src, project_dir / "TOOL_REFERENCE.md")
            print(f"  Copied:    TOOL_REFERENCE.md")


def _fixup_global_hook_path(settings_path: Path) -> None:
    """Replace $CLAUDE_PROJECT_DIR hook paths with absolute ~/.aiir/hooks/ path."""
    try:
        data = json.loads(settings_path.read_text())
    except (json.JSONDecodeError, OSError):
        return

    abs_hook = str(Path.home() / ".aiir" / "hooks" / "forensic-audit.sh")
    changed = False

    for hook_type in ("PostToolUse", "UserPromptSubmit"):
        entries = data.get("hooks", {}).get(hook_type, [])
        for entry in entries:
            for h in entry.get("hooks", []):
                cmd = h.get("command", "")
                if "$CLAUDE_PROJECT_DIR" in cmd and "forensic-audit.sh" in cmd:
                    h["command"] = abs_hook
                    changed = True

    if changed:
        _write_600(settings_path, json.dumps(data, indent=2) + "\n")


def _merge_and_write(path: Path, config: dict) -> None:
    """Write config, merging with existing file if present."""
    existing = {}
    if path.is_file():
        try:
            existing = json.loads(path.read_text())
        except json.JSONDecodeError as e:
            print(
                f"Warning: existing config {path} has invalid JSON ({e}), overwriting.",
                file=sys.stderr,
            )
        except OSError as e:
            print(
                f"Warning: could not read existing config {path}: {e}", file=sys.stderr
            )

    # Merge: existing servers are preserved, AIIR servers overwritten
    existing_servers = existing.get("mcpServers", {})
    existing_servers.update(config.get("mcpServers", {}))
    existing["mcpServers"] = existing_servers

    try:
        path.parent.mkdir(parents=True, exist_ok=True)
    except OSError as e:
        print(f"Failed to create directory {path.parent}: {e}", file=sys.stderr)
        raise
    _write_600(path, json.dumps(existing, indent=2) + "\n")


def _write_librechat_yaml(path: Path, servers: dict) -> None:
    """Write LibreChat mcpServers YAML snippet."""
    lines = ["# AIIR MCP servers — merge into your librechat.yaml", "mcpServers:"]
    for name, info in servers.items():
        # Skip non-streamable-http entries (Claude Desktop npx bridge)
        if "url" not in info:
            continue
        lines.append(f"  {name}:")
        lines.append(f'    type: "{info["type"]}"')
        lines.append(f'    url: "{info["url"]}"')
        headers = info.get("headers")
        if headers:
            lines.append("    headers:")
            for hk, hv in headers.items():
                lines.append(f'      {hk}: "{hv}"')
        lines.append("    timeout: 60000")
        lines.append("    serverInstructions: true")
    path.parent.mkdir(parents=True, exist_ok=True)
    _write_600(path, "\n".join(lines) + "\n")


_AGENTS_MD_CANDIDATES = [
    lambda: Path.cwd() / "AGENTS.md",
    lambda: Path.home() / ".aiir" / "src" / "sift-mcp" / "AGENTS.md",
    lambda: Path.home() / "aiir" / "sift-mcp" / "AGENTS.md",
    lambda: Path.home() / "aiir" / "forensic-mcp" / "AGENTS.md",
    lambda: Path("/opt/aiir/sift-mcp") / "AGENTS.md",
    lambda: Path("/opt/aiir") / "AGENTS.md",
]


def _find_agents_md() -> Path | None:
    """Find AGENTS.md from known locations. Returns path or None."""
    for candidate_fn in _AGENTS_MD_CANDIDATES:
        src = candidate_fn()
        if src.is_file():
            return src
    return None


def _copy_agents_md(target: Path) -> None:
    """Copy AGENTS.md from sift-mcp monorepo as the client instruction file."""
    src = _find_agents_md()
    if src:
        try:
            shutil.copy2(src, target)
            print(f"  Copied:    {src.name} -> {target.name}")
        except OSError as e:
            print(f"  Warning: failed to copy {src} to {target}: {e}", file=sys.stderr)
    else:
        print(
            "  Warning: AGENTS.md not found. Copy it manually from the sift-mcp repo."
        )


def _write_cursor_rules() -> None:
    """Write .cursor/rules/aiir.mdc (modern) + .cursorrules (legacy fallback)."""
    src = _find_agents_md()
    if not src:
        print(
            "  Warning: AGENTS.md not found. Copy it manually from the sift-mcp repo."
        )
        return

    content = src.read_text()

    # Modern Cursor (v0.47+): .cursor/rules/aiir.mdc with YAML frontmatter
    rules_dir = Path.cwd() / ".cursor" / "rules"
    rules_dir.mkdir(parents=True, exist_ok=True)
    mdc_path = rules_dir / "aiir.mdc"
    mdc_content = (
        "---\n"
        "description: AIIR forensic investigation rules\n"
        "alwaysApply: true\n"
        "---\n"
        f"{content}\n"
    )
    mdc_path.write_text(mdc_content)
    print(f"  Generated: {mdc_path}")

    # Legacy fallback: .cursorrules
    legacy = Path.cwd() / ".cursorrules"
    try:
        shutil.copy2(src, legacy)
        print(f"  Copied:    {src.name} -> {legacy.name}")
    except OSError as e:
        print(f"  Warning: failed to copy {src} to {legacy}: {e}", file=sys.stderr)


# ---------------------------------------------------------------------------
# Uninstall
# ---------------------------------------------------------------------------


def _cmd_uninstall(args) -> None:
    """Remove AIIR forensic controls with interactive per-component approval."""
    sift = _is_sift()

    print("\nAIIR Forensic Controls — Uninstall\n")

    if sift:
        _uninstall_sift()
        print("\nTo remove the full SIFT platform (gateway, venv, source):")
        print("  setup-sift.sh --uninstall")
    else:
        _uninstall_project()


def _uninstall_sift() -> None:
    """SIFT global uninstall — interactive per-component removal."""
    # [1] MCP servers from ~/.claude.json
    claude_json = Path.home() / ".claude.json"
    if claude_json.is_file():
        print("  [1] MCP servers (~/.claude.json mcpServers)")
        print("      Only AIIR backend entries are removed. Others preserved.")
        if _prompt_yn("      Remove?", default=False):
            _remove_aiir_mcp_entries(claude_json)
            print("      Removed AIIR MCP entries.")
        else:
            print("      Skipped.")
    print()

    # [2] Hooks & permissions from ~/.claude/settings.json
    settings = Path.home() / ".claude" / "settings.json"
    if settings.is_file():
        print("  [2] Hooks & permissions (~/.claude/settings.json)")
        print("      Forensic entries only. Other settings preserved.")
        if _prompt_yn("      Remove?", default=False):
            _remove_forensic_settings(settings)
            print("      Removed forensic settings.")
        else:
            print("      Skipped.")
    print()

    # [3] Hook script
    hook = Path.home() / ".aiir" / "hooks" / "forensic-audit.sh"
    if hook.is_file():
        print("  [3] Audit hook script (~/.aiir/hooks/forensic-audit.sh)")
        if _prompt_yn("      Remove?", default=False):
            hook.unlink()
            print("      Removed.")
        else:
            print("      Skipped.")
    print()

    # [4] Discipline docs
    claude_md = Path.home() / ".claude" / "CLAUDE.md"
    rules_dir = Path.home() / ".claude" / "rules"
    has_docs = claude_md.is_file() or rules_dir.is_dir()
    if has_docs:
        print("  [4] Discipline docs")
        if claude_md.is_file():
            print(f"      {claude_md}")
        for name in ("FORENSIC_DISCIPLINE.md", "TOOL_REFERENCE.md", "AGENTS.md"):
            p = rules_dir / name
            if p.is_file():
                print(f"      {p}")
        if _prompt_yn("      Remove?", default=False):
            if claude_md.is_file():
                claude_md.unlink()
                # Restore backup if exists
                bak = claude_md.with_suffix(".md.bak")
                if bak.is_file():
                    bak.rename(claude_md)
                    print("      Restored CLAUDE.md from backup.")
            for name in ("FORENSIC_DISCIPLINE.md", "TOOL_REFERENCE.md", "AGENTS.md"):
                p = rules_dir / name
                if p.is_file():
                    p.unlink()
            print("      Removed discipline docs.")
        else:
            print("      Skipped.")
    print()

    # [5] Project-level files
    project_files = ["CLAUDE.md", "AGENTS.md", "FORENSIC_DISCIPLINE.md", "TOOL_REFERENCE.md"]
    existing_project = [f for f in project_files if (Path.cwd() / f).is_file()]
    if existing_project:
        print("  [5] Project-level files (in current directory)")
        for f in existing_project:
            print(f"      {f}")
        if _prompt_yn("      Remove?", default=False):
            for f in existing_project:
                (Path.cwd() / f).unlink()
            print("      Removed.")
        else:
            print("      Skipped.")

    print("\nUninstall complete.")


def _uninstall_project() -> None:
    """Non-SIFT project-level uninstall."""
    project_dir = Path.cwd()
    claude_dir = project_dir / ".claude"
    mcp_json = project_dir / ".mcp.json"

    files_to_remove = []
    for name in ("AGENTS.md", "FORENSIC_DISCIPLINE.md", "TOOL_REFERENCE.md"):
        p = project_dir / name
        if p.is_file():
            files_to_remove.append(p)

    claude_md = project_dir / "CLAUDE.md"
    has_claude_md = claude_md.is_file()
    if has_claude_md:
        files_to_remove.append(claude_md)

    has_mcp_json = mcp_json.is_file()

    # Surgical .claude/ removal — only remove AIIR files, not user settings
    claude_files_to_remove: list[Path] = []
    if claude_dir.is_dir():
        settings_file = claude_dir / "settings.json"
        hooks_dir = claude_dir / "hooks"
        hook_file = hooks_dir / "forensic-audit.sh"
        if hook_file.is_file():
            claude_files_to_remove.append(hook_file)
        if settings_file.is_file():
            claude_files_to_remove.append(settings_file)

    if not files_to_remove and not claude_files_to_remove and not has_mcp_json:
        print("  No AIIR files found in current directory.")
        return

    print("  Files to remove:")
    for p in files_to_remove:
        print(f"    {p}")
    if has_mcp_json:
        print(f"    {mcp_json} (AIIR entries only)")
    for p in claude_files_to_remove:
        print(f"    {p}")

    if _prompt_yn("  Remove all?", default=False):
        for p in files_to_remove:
            p.unlink()
        # Surgical .mcp.json removal — only AIIR entries
        if has_mcp_json:
            _remove_aiir_mcp_entries(mcp_json)
        # Restore CLAUDE.md backup if exists
        if has_claude_md:
            bak = claude_md.with_suffix(".md.bak")
            if bak.is_file():
                bak.rename(claude_md)
                print("  Restored CLAUDE.md from backup.")
        # Surgical settings removal instead of rmtree
        for p in claude_files_to_remove:
            if p.name == "settings.json":
                _remove_forensic_settings(p)
            else:
                p.unlink()
        # Clean up empty hooks dir
        hooks_dir = claude_dir / "hooks"
        if hooks_dir.is_dir() and not any(hooks_dir.iterdir()):
            hooks_dir.rmdir()
        print("  Removed.")
    else:
        print("  Skipped.")

    print("\nUninstall complete.")


def _remove_aiir_mcp_entries(path: Path) -> None:
    """Remove AIIR backend entries from ~/.claude.json mcpServers."""
    try:
        data = json.loads(path.read_text())
    except (json.JSONDecodeError, OSError):
        return
    servers = data.get("mcpServers", {})
    for name in list(servers.keys()):
        if name in _AIIR_BACKEND_NAMES:
            del servers[name]
    _write_600(path, json.dumps(data, indent=2) + "\n")


def _remove_forensic_settings(path: Path) -> None:
    """Remove forensic-specific entries from settings.json, preserve rest."""
    try:
        data = json.loads(path.read_text())
    except (json.JSONDecodeError, OSError):
        return

    # Remove forensic hooks
    hooks = data.get("hooks", {})
    for hook_type in ("PostToolUse", "UserPromptSubmit"):
        entries = hooks.get(hook_type, [])
        hooks[hook_type] = [
            e for e in entries
            if not any("forensic-audit" in h.get("command", "") for h in e.get("hooks", []))
            and not any("forensic-rules" in h.get("command", "") for h in e.get("hooks", []))
        ]
        if not hooks[hook_type]:
            del hooks[hook_type]
    if not hooks:
        data.pop("hooks", None)

    # Remove forensic deny rules
    perms = data.get("permissions", {})
    deny = perms.get("deny", [])
    perms["deny"] = [r for r in deny if r not in _FORENSIC_DENY_RULES]
    if not perms["deny"]:
        perms.pop("deny", None)
    if not perms:
        data.pop("permissions", None)

    # Remove sandbox
    data.pop("sandbox", None)

    _write_600(path, json.dumps(data, indent=2) + "\n")


# ---------------------------------------------------------------------------
# Helpers
# ---------------------------------------------------------------------------


def _read_local_token() -> str | None:
    """Read the first api_key from ~/.aiir/gateway.yaml.

    The api_keys format in gateway.yaml is a dict keyed by token string:
        api_keys:
          aiir_gw_abc123...:
            examiner: "default"
            role: "lead"
    So next(iter(api_keys)) returns the token string itself.
    """
    config_path = Path.home() / ".aiir" / "gateway.yaml"
    if not config_path.is_file():
        return None
    try:
        import yaml

        config = yaml.safe_load(config_path.read_text()) or {}
        api_keys = config.get("api_keys", {})
        if isinstance(api_keys, dict) and api_keys:
            return next(iter(api_keys))
        return None
    except Exception:
        return None


def _normalise_url(raw: str, default_port: int) -> str:
    """Turn ``IP:port`` or bare ``IP`` into ``http://IP:port``."""
    raw = raw.strip()
    if not raw:
        return ""
    # Reject obviously invalid input
    if any(c in raw for c in (" ", "\t", "\n", "<", ">", '"', "'")):
        print(f"Warning: invalid characters in URL input: {raw!r}", file=sys.stderr)
        return ""
    if raw.startswith("http://") or raw.startswith("https://"):
        return raw
    if ":" not in raw:
        raw = f"{raw}:{default_port}"
    return f"http://{raw}"


def _ensure_mcp_path(url: str) -> str:
    """Ensure URL ends with /mcp."""
    url = url.rstrip("/")
    if not url.endswith("/mcp"):
        url += "/mcp"
    return url


def _probe_health(base_url: str) -> bool:
    """Try to reach a /health endpoint."""
    try:
        import urllib.request

        url = f"{base_url.rstrip('/')}/health"
        req = urllib.request.Request(url, method="GET")
        with urllib.request.urlopen(req, timeout=5) as resp:
            return resp.status == 200
    except OSError as e:
        # Network/connection errors (includes URLError, socket.error)
        import logging

        logging.debug("Health probe failed for %s: %s", base_url, e)
        return False
    except Exception as e:
        import logging

        logging.debug("Health probe unexpected error for %s: %s", base_url, e)
        return False


# ---------------------------------------------------------------------------
# Remote setup mode
# ---------------------------------------------------------------------------


def _cmd_setup_client_remote(args, identity: dict) -> None:
    """Generate client config pointing at a remote AIIR gateway.

    Discovers running backends via the service management API, then builds
    per-backend MCP endpoint entries with bearer token auth.
    """
    auto = getattr(args, "yes", False)
    client = _resolve_client(args, auto)
    examiner = _resolve_examiner(args, identity)

    # 1. Resolve gateway URL
    gateway_url = getattr(args, "sift", None)
    if not gateway_url:
        if auto:
            print("ERROR: --sift is required with --remote -y", file=sys.stderr)
            sys.exit(1)
        gateway_url = _prompt("Gateway URL (e.g., https://sift.example.com:4508)", "")
    if not gateway_url:
        print("ERROR: Gateway URL is required for remote setup.", file=sys.stderr)
        sys.exit(1)
    gateway_url = gateway_url.rstrip("/")

    # 2. Resolve bearer token
    token = getattr(args, "token", None)
    if not token:
        if auto:
            print("ERROR: --token is required with --remote -y", file=sys.stderr)
            sys.exit(1)
        token = _prompt("Bearer token", "")

    # 3. Test connectivity
    print(f"\nConnecting to {gateway_url} ...")
    health = _probe_health_with_auth(gateway_url, token)
    if health is None:
        print(f"ERROR: Cannot reach gateway at {gateway_url}", file=sys.stderr)
        sys.exit(1)
    print(f"  Gateway status: {health.get('status', 'unknown')}")

    # 4. Discover backends via service management API
    services = _discover_services(gateway_url, token)
    if services is None:
        print("ERROR: Failed to discover services from gateway.", file=sys.stderr)
        sys.exit(1)

    running = [s for s in services if s.get("started")]
    if not running:
        print("WARNING: No running backends found on gateway.", file=sys.stderr)

    print(f"  Backends: {len(running)} running")
    for s in running:
        print(f"    {s['name']}")

    # 5. Build endpoint entries
    servers: dict[str, dict] = {}

    # Per-backend endpoints
    for s in running:
        name = s["name"]
        servers[name] = _format_server_entry(
            client,
            f"{gateway_url}/mcp/{name}",
            token,
        )

    # 6. Windows / internet MCPs (same as local)
    windows_url = _resolve_windows(args, auto)
    if windows_url:
        servers["wintools-mcp"] = {
            "type": "streamable-http",
            "url": _ensure_mcp_path(windows_url),
        }

    include_zeltser, include_mslearn = _resolve_internet_mcps(args, auto)
    if include_zeltser:
        servers[_ZELTSER_MCP["name"]] = {
            "type": _ZELTSER_MCP["type"],
            "url": _ZELTSER_MCP["url"],
        }
    if include_mslearn:
        servers[_MSLEARN_MCP["name"]] = {
            "type": _MSLEARN_MCP["type"],
            "url": _MSLEARN_MCP["url"],
        }

    if not servers:
        print("No endpoints configured — nothing to write.", file=sys.stderr)
        return

    # 7. Generate config
    try:
        _generate_config(client, servers, examiner)
    except OSError as e:
        print(f"Failed to write client configuration: {e}", file=sys.stderr)
        sys.exit(1)

    # 8. Save gateway config for `aiir service` commands
    _save_gateway_config(gateway_url, token)

    print(f"\n  Remote setup complete. Examiner: {examiner}")


def _format_server_entry(client: str, url: str, token: str | None) -> dict:
    """Format a server entry appropriate for the target client.

    Claude Desktop needs mcp-remote bridge (npx subprocess) because it
    doesn't support streamable-http natively. Other clients use native
    streamable-http with Authorization header.
    """
    if client == "claude-desktop" and token:
        if not shutil.which("npx"):
            raise SystemExit(
                "Claude Desktop requires npx (Node.js) for mcp-remote bridge.\n"
                "Install Node.js: https://nodejs.org/ or: sudo apt install nodejs npm"
            )
        return {
            "command": "npx",
            "args": [
                "-y",
                "mcp-remote",
                url,
                "--header",
                "Authorization:${AUTH_HEADER}",
            ],
            "env": {"AUTH_HEADER": f"Bearer {token}"},
        }

    entry: dict = {
        "type": "streamable-http",
        "url": url,
    }
    if token:
        entry["headers"] = {"Authorization": f"Bearer {token}"}
    return entry


def _probe_health_with_auth(base_url: str, token: str | None) -> dict | None:
    """Probe /health with optional bearer token. Returns parsed dict or None."""
    import urllib.request

    try:
        url = f"{base_url.rstrip('/')}/health"
        req = urllib.request.Request(url, method="GET")
        if token:
            req.add_header("Authorization", f"Bearer {token}")
        with urllib.request.urlopen(req, timeout=5) as resp:
            if resp.status == 200:
                import json as _json

                return _json.loads(resp.read())
    except OSError:
        pass
    except Exception:
        pass
    return None


def _discover_services(base_url: str, token: str | None) -> list | None:
    """GET /api/v1/services and return the services list, or None on failure."""
    import urllib.request

    try:
        url = f"{base_url.rstrip('/')}/api/v1/services"
        req = urllib.request.Request(url, method="GET")
        if token:
            req.add_header("Authorization", f"Bearer {token}")
        with urllib.request.urlopen(req, timeout=5) as resp:
            if resp.status == 200:
                import json as _json

                data = _json.loads(resp.read())
                return data.get("services", [])
    except OSError:
        pass
    except Exception:
        pass
    return None


def _save_gateway_config(url: str, token: str | None) -> None:
    """Save gateway URL and token to ~/.aiir/config.yaml."""
    import yaml

    config_dir = Path.home() / ".aiir"
    config_file = config_dir / "config.yaml"

    existing = {}
    if config_file.is_file():
        try:
            existing = yaml.safe_load(config_file.read_text()) or {}
        except Exception:
            pass

    existing["gateway_url"] = url
    if token:
        existing["gateway_token"] = token

    try:
        config_dir.mkdir(parents=True, exist_ok=True)
        _write_600(config_file, yaml.dump(existing, default_flow_style=False))
    except OSError as e:
        print(f"Warning: could not save gateway config: {e}", file=sys.stderr)
